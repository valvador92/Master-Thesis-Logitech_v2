\section{Conclusion}
\label{section:conclusion}

The different results shown in this report demonstrates the possibility of using 3D point clouds video stream for the meeting room of the future. It enables virtual viewpoint to improve the immersion feeling. The use cases scenarios demonstrate this idea of free viewpoint.

However, the technology is capricious and a lot of processing is needed to have an acceptable rendering of the scene. All the captured views have to be first well aligned. The proposed registration approach worked good with two views and should be easily generalised to more views. But this developed algorithm has to be done offline, requires its own calibration data and have to be remade each time the place of the camera is changing. Developing an accurate registration based on known keypoints in the room instead of ChArUco corners could be an approach to avoid capturing specific data for this registration step. This thesis proposed also solutions to some of the most visually impactful issues like colour inconsistency, flickering effect and noise on the edges. The statistic approach improving the colour consistency corrects only partially the problem. It is a good initial correction but other algorithms should be added after that one to discard completely the differences. The anti-flickering proposed method has a significant impact. However, the flickering effect is still visible and other methods like fitting data onto a model could be investigated to resolve completely this problem. Using more than two cameras could really improve the rendering by increasing the covered volume. All these potential improvements be tried in a future work.


'Holes', that appear for example when hands are moving in front of another body part, is the most visually impactful problem that was not handled in this project. Using past information to fill these 'holes' could be a way to tackle this issue. Using 3D models of a human body could be another one. Finding a solution to this problem should be investigated in a future work.

Point cloud is the chosen 3D representation of the data chosen in this project. Is it the appropriate format for 3D video stream? This question is not answered. Textured meshes should be considered as an alternative. A comparison between these two ways of representing 3D data could be the subject for another future work to assess which one is more suitable for a video conference scenario.
% The proposed methods correct only partially Some aspects were not handled like using past information to fill holes when data are missing. This approach should be investigated in a future work. It could improve the visual rendering of the scene and therefore improve the immersion.  Is the point cloud the appropriate 3D representation of the data for a video stream? This question could be asked and is not answered in this project. Point cloud have the big advantage of having the possibility to be created straightly from a RGB-D cameras. Furthermore, these dense point clouds look natural. Mesh can always be created from point cloud. Therefore another work could investigate this other 3D representation for meeting room scenarios.

Despite all the limitation developed in this thesis, dense point cloud is a 3D visualisation format that is promising for the future of 3D video streaming because it is easily created from a RGB-D camera device and because the rendering looks natural.